{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1e685bf-3536-41c9-b283-c4b47d406290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define widgets with default values\n",
    "dbutils.widgets.text(\"quote_id\", \"R9999\")\n",
    "dbutils.widgets.text(\"catalog\", \"lrcatalog\")\n",
    "dbutils.widgets.text(\"schema\", \"agentic_underwriting\")\n",
    "\n",
    "#%pip install -U databricks-agents databricks-openai databricks-langchain mlflow\n",
    "#dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5cef428-5b0a-496f-a457-cd132d1b9b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get widget values\n",
    "quote_id = dbutils.widgets.get(\"quote_id\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b1ada23-c756-49f4-badb-1c79d07de930",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Here we start with tool definitions for our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f90a73f8-445c-46fd-8066-311702b04d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🔍 Function: `make_get_quote_details`\n",
    "\n",
    "This function factory returns a callable that retrieves details of a specific motor insurance quote from the `quotes` table in the specified catalog and schema.\n",
    "\n",
    "- **Input:** `quote_id` (case-insensitive, trimmed string)\n",
    "- **Output:** Markdown-formatted table with quote details, or an error message if not found\n",
    "- **Use case:** Can be plugged into LangChain agents or UI apps to display quote details based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b2986e-2c3f-4cd5-a10b-3c3f12241c90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_get_quote_details(catalog, schema):\n",
    "    def _fn(quote_id: str) -> str:\n",
    "        quote_id_clean = quote_id.strip()\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT * FROM {catalog}.{schema}.quotes\n",
    "            WHERE LOWER(quote_id) = LOWER('{quote_id_clean}')\n",
    "        \"\"\").toPandas()\n",
    "\n",
    "        if df.empty:\n",
    "            return f\"🚫 Quote not found for quote_id: {quote_id_clean}\"\n",
    "        \n",
    "        markdown = df.to_markdown(index=False)\n",
    "        return f\"✅ Quote found:\\n\\n{markdown}\"\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "544e5c63-8a7f-4bcc-8979-f31f020af79c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🔍 Function: `make_validate_claims`\n",
    "\n",
    "This function factory creates a callable that validates disclosed claims for a customer based on their full name and postcode.\n",
    "\n",
    "- **Input:** A string in the format `'First Last, POSTCODE'`\n",
    "- **Output:** A Markdown-formatted table of matching claim validation records, or an error message\n",
    "- **Use case:** Useful in LangChain agents or UI flows to check if the customer’s disclosed claims match stored records before underwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1563a9a3-ded5-4833-a5a2-75cf991718c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_validate_claims(catalog, schema):\n",
    "    def _fn(full_name_and_postcode: str) -> str:\n",
    "        def escape_sql(value: str) -> str:\n",
    "            return value.replace(\"'\", \"''\")\n",
    "\n",
    "        try:\n",
    "            name_part, postcode = full_name_and_postcode.rsplit(\",\", 1)\n",
    "            first_name, last_name = name_part.strip().split(\" \", 1)\n",
    "        except ValueError:\n",
    "            return \"Please provide input as 'First Last, POSTCODE'.\"\n",
    "\n",
    "        first_name = escape_sql(first_name.strip())\n",
    "        last_name = escape_sql(last_name.strip())\n",
    "        postcode = escape_sql(postcode.strip())\n",
    "\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT * FROM {catalog}.{schema}.claims_disclosure_validation\n",
    "            WHERE first_name = '{first_name}' AND last_name = '{last_name}' AND postcode = '{postcode}'\n",
    "        \"\"\").toPandas()\n",
    "\n",
    "        if df.empty:\n",
    "            return \"No claims record found for this name and postcode.\"\n",
    "        return df.to_markdown(index=False)\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5f5f04f-b889-49ac-abc5-3aa5cfa5e6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🔍 Function: `make_get_call_transcript`\n",
    "\n",
    "This function factory returns a callable that retrieves the call transcript associated with a specific motor insurance quote from the `sales_call_transcripts` table.\n",
    "\n",
    "- **Input:** `quote_id` (string)\n",
    "- **Output:** Raw text of the call transcript, or a message if no transcript is found\n",
    "- **Use case:** Can be used in LangChain agents or apps to provide customer interaction history for underwriting or sales analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "217df6b8-f613-45b3-a6bf-d7d33b747960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_get_call_transcript(catalog, schema):\n",
    "    def _fn(quote_id: str) -> str:\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT call_transcript\n",
    "            FROM {catalog}.{schema}.sales_call_transcripts\n",
    "            WHERE quote_id = '{quote_id}'\n",
    "        \"\"\").toPandas()\n",
    "\n",
    "        if df.empty:\n",
    "            return f\"No call transcript available for quote ID: {quote_id}\"\n",
    "\n",
    "        return df.iloc[0][\"call_transcript\"]\n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e56e03a-e7c1-4a53-b73d-6d8549aa1567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🔍 Function: `score_quote_tool`\n",
    "\n",
    "This function scores a motor insurance quote using a basic risk model based on age, vehicle type, number of claims, and no claims discount (NCD).\n",
    "\n",
    "- **Input:** A dictionary or JSON string with keys: `age`, `vehicle_type`, `ncd_declared`, and `claims_declared`\n",
    "- **Output:** A dictionary containing the calculated `price`, the `model_name`, and optionally an `error` message\n",
    "- **Use case:** Can be used in LangChain agents or quote evaluation tools to simulate a pricing model based on risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f56fd08-04b0-46f9-8d7b-bf2b08246e2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def score_quote_tool(inputs) -> dict:\n",
    "    \"\"\"\n",
    "    Accepts either a dictionary or a JSON string with keys:\n",
    "    age, vehicle_type, ncd_declared, claims_declared, storage_declared.\n",
    "    Returns a dict with price and model name.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(inputs, str):\n",
    "        try:\n",
    "            inputs = json.loads(inputs)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\n",
    "                \"price\": None,\n",
    "                \"model_name\": \"standard_risk_model\",\n",
    "                \"error\": \"Invalid input: cannot parse JSON input string.\"\n",
    "            }\n",
    "\n",
    "    def to_number_or_empty(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return ''\n",
    "\n",
    "    # Extract values safely\n",
    "    age = to_number_or_empty(inputs.get(\"age\"))\n",
    "    vehicle_type = (inputs.get(\"vehicle_type\") or '').strip()\n",
    "    ncd_declared = to_number_or_empty(inputs.get(\"ncd_declared\"))\n",
    "    claims_declared = to_number_or_empty(inputs.get(\"claims_declared\"))\n",
    "    storage_declared = (inputs.get(\"storage_declared\") or '').strip().lower()\n",
    "\n",
    "    # Validate required numeric fields\n",
    "    if '' in (age, ncd_declared, claims_declared):\n",
    "        return {\n",
    "            \"price\": None,\n",
    "            \"model_name\": \"standard_risk_model\",\n",
    "            \"error\": \"Invalid input: age, ncd_declared, and claims_declared must be numbers.\"\n",
    "        }\n",
    "\n",
    "    # Pricing logic\n",
    "    base_price = 500\n",
    "    claim_adj = claims_declared * 100\n",
    "\n",
    "    vehicle_mult = {\n",
    "        \"SUV\": 1.2,\n",
    "        \"Hatchback\": 1.0,\n",
    "        \"Sports\": 1.5\n",
    "    }.get(vehicle_type, 1.1)\n",
    "\n",
    "    if age < 25:\n",
    "        age_adj = 200\n",
    "    elif age < 35:\n",
    "        age_adj = 100\n",
    "    else:\n",
    "        age_adj = 0\n",
    "\n",
    "    storage_adj = {\n",
    "        \"garage\": -50,\n",
    "        \"driveway\": 0,\n",
    "        \"street\": 50\n",
    "    }.get(storage_declared, 25)  # fallback adjustment\n",
    "\n",
    "    ncd_adj = ncd_declared * 30\n",
    "\n",
    "    quote_value = round((base_price + claim_adj + age_adj + storage_adj - ncd_adj) * vehicle_mult, 2)\n",
    "\n",
    "    return {\n",
    "        \"price\": quote_value,\n",
    "        \"model_name\": \"standard_risk_model\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b51cc7-b9ea-4ce2-8bf5-c3f01778c696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🏡 Function: `validate_property_attributes`\n",
    "\n",
    "This function retrieves property-level risk data for a given postcode, such as garage and driveway availability and overall property risk level.\n",
    "\n",
    "- **Input:** A UK postcode as a plain string (e.g., `'CR3 6JE'`)\n",
    "- **Output:** A markdown table of the matching row from the `property_attributes` table, or a message if no match is found\n",
    "- **Use case:** Used in LangChain agents or underwriting pipelines to enrich or validate property context based on location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231aa718-c098-4021-9746-a595567819af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_validate_property_attributes(catalog, schema):\n",
    "    def _fn(postcode: str) -> str:\n",
    "        def escape_sql(value: str) -> str:\n",
    "            return value.replace(\"'\", \"''\")\n",
    "\n",
    "        postcode = escape_sql(postcode.strip())\n",
    "\n",
    "        df = spark.sql(f\"\"\"\n",
    "            SELECT * FROM {catalog}.{schema}.property_attributes\n",
    "            WHERE postcode = '{postcode}'\n",
    "        \"\"\").toPandas()\n",
    "\n",
    "        if df.empty:\n",
    "            return f\"No property record found for postcode '{postcode}'.\"\n",
    "        return df.to_markdown(index=False)\n",
    "    \n",
    "    return _fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880679a5-b161-429a-9455-094baed052a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def make_get_driver_risk(catalog, schema):\n",
    "#     def _fn(age_str: str) -> str:\n",
    "#         def escape_sql(v): return v.replace(\"'\", \"''\")\n",
    "#         try:\n",
    "#             age = int(age_str)\n",
    "#         except ValueError:\n",
    "#             return \"Please provide a valid age as a number.\"\n",
    "\n",
    "#         df = spark.sql(f\"\"\"\n",
    "#             SELECT * FROM {catalog}.{schema}.driver_risk_profile\n",
    "#             WHERE age = {age}\n",
    "#         \"\"\").toPandas()\n",
    "\n",
    "#         if df.empty:\n",
    "#             return f\"No risk profile found for age {age}.\"\n",
    "#         return df.to_markdown(index=False)\n",
    "#     return _fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e32590-4ad1-4401-bb15-c0c29107adc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🧰 Tool Definitions for LangChain Agent\n",
    "\n",
    "This section defines the set of tools available to the LangChain agent, each wrapping a callable function with a clear name and description.\n",
    "\n",
    "- **Tools included:**\n",
    "  - `Get Quote Details`: Returns declared customer and quote info by quote ID\n",
    "  - `Validate Claims`: Returns verified NCD and claims using name and postcode\n",
    "  - `Get Call Transcript`: Retrieves the sales call transcript for a quote ID\n",
    "  - `Score Quote`: Calculates a new quote price using risk-based inputs\n",
    "\n",
    "- **Use case:** These tools enable the agent to retrieve and cross-check underwriting data, simulate new pricing, and analyze sales interactions in real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d3a613c-d914-48e7-9866-26cebb31bfb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(make_get_quote_details(catalog, schema), name=\"Get Quote Details\",description=\"Returns the declared quote data including first name, last name, postcode, age, vehicle type, declared claims and declared NCD. Input Use this to compare with validated data. Input just the quote ID value.\"),\n",
    "    Tool.from_function(make_validate_claims(catalog, schema), name=\"Validate Claims\", description=\"Returns the verified amount of claims and NCD for the given person. Compare these with what the customer declared in the quote using first name, last name and postcode.  Input two values: name and postcode. \"),\n",
    "    Tool.from_function(make_get_call_transcript(catalog, schema), name=\"Get Call Transcript\", description=\"Returns the sales call transcript for a given quote ID if available. Analyse transcript data and compare with what the quote and validation data claim. Look for any potential errors of sales representative, for example mixed values in fields.\"),\n",
    "    Tool.from_function(score_quote_tool, name=\"Score Quote\", description=\"Returns a price and model version used to generate it. Input values in this format {{\\\"age\\\": 32, \\\"vehicle_type\\\": \\\"SUV\\\", \\\"ncd_declared\\\": 6, \\\"claims_declared\\\": 3, \\\"storage_declared\\\": \\\"garage\\\"}}. Can be used to create a new price.\"),\n",
    "    Tool.from_function(make_validate_property_attributes(catalog, schema), name=\"Validate Property Attributes\", description=(\"Returns property attributes for a given postcode, such as has_garage, has_driveway, and property_risk_level. Input must be a UK postcode in the format: 'CR3 6JE'. Useful for enriching underwriting decisions with contextual property risk data.\")\n",
    "    )\n",
    "    #Tool.from_function(make_get_driver_risk(catalog, schema), name=\"Get Driver Risk\", description=\"Get the risk segment for a postcode.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a12ddba-fe98-4ec3-9e6f-967887a235c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 🧠 Agent Initialization\n",
    "\n",
    "This cell initializes a LangChain agent using a Databricks-hosted LLM (`meta-llama-3-1-70b-instruct`) and a set of predefined tools.\n",
    "\n",
    "- **LLM:** `ChatDatabricks` connected to a specified endpoint\n",
    "- **Agent type:** `ZERO_SHOT_REACT_DESCRIPTION` — allows reasoning over tool descriptions without examples\n",
    "- **Settings:**\n",
    "  - `verbose=True` for step-by-step logging\n",
    "  - `handle_parsing_errors=True` to gracefully manage response formatting issues\n",
    "\n",
    "- **Use case:** Powers a dynamic, tool-using agent capable of answering insurance-related questions or performing quote evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e17ace32-18fb-4077-9d21-59f6f5ebb349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "llm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d11549a-cc01-44bf-b927-fb72db55131c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 📝 Agent Execution Workflow\n",
    "\n",
    "This cell runs a multi-step underwriting evaluation process through the LangChain agent using the specified quote ID.\n",
    "\n",
    "- **Goal:** Assist an underwriter in checking quote accuracy and flagging issues before approval\n",
    "- **Steps:**\n",
    "  1. **Get Quote Details** – fetch declared quote information\n",
    "  2. **Validate Claims** – check against verified claims/NCD data\n",
    "  3. **Get Call Transcript** – verify customer disclosures against quote data\n",
    "  4. **Identify Errors** – if call center input error is suspected, rescore using `Score Quote`\n",
    "  5. **Summarize** – return a comprehensive decision message\n",
    "\n",
    "- **Use case:** Enables end-to-end decision support with data validation, transcript analysis, and dynamic pricing review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d54efe5-62f7-40a1-86eb-dbf22873ee15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "agent_output = agent.run(f\"\"\"\n",
    "You are an underwriter for motor insurance policies. You will check a quote and decide whether it should be approved or reviewed.\n",
    "\n",
    "Step 1: Use the 'Get Quote Details' tool with quote ID {quote_id}. If the quote is not found, respond with a message and stop the process. Otherwise, get the quote details and Return the message.\n",
    "\n",
    "Step 2: Use the 'Validate Claims'. If the customer does not exist in validation data, flag potential fraud, respond with correct message and stop this process. Otherwise check the number of claims and ncd, compare to the quote and decide if it should be approved or reviewed. Return the relevant message.\n",
    "\n",
    "Step 3: Use the 'Get Call Transcript' tool to retrieve the sales call for this quote. Check if the values mentioned by the customer in the call (e.g. postcode, vehicle type, NCD, claims) match what is shown in the quote. If the customer provided correct details in the call, but the quote shows different values, this may indicate an error made by the call handler.\n",
    "\n",
    "Step 4: Use the 'Validate Property Attributes' tool to retrieve the property details for this postcode. Check if the returned attributes (e.g. has_garage, has_driveway, property_risk_level) align with what is assumed or declared in the quote. If the quote relies on incorrect property assumptions—for example, assuming a garage where none exists—this could indicate an underwriting error or misclassification. Flag the mismatch and suggest review, then run Step 5 for new quote with corrected parameters. Ensure to include in description the results of the search in comparison to the quote data. If no mismatch skip Step 5 and go to Step 6.\n",
    "\n",
    "Step 5: Don't use this if the data matches in previous steps or if there is no call transcript. If a mismatch was likely caused by incorrect data entry during the call, note this and suggest review. Use 'Score Quote' tool to create a new price with corrected values.  Otherwise, list all mismatches clearly. Return full description of this process.\n",
    "\n",
    "Step 6: Summarize above steps in points with details on what tools were used and their results. Ensure to include all details regarding data you have gathered during previous steps. Say if the quote should be approved or rejected. Add a dad joke at the end.\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8036997e-b5a6-4257-8eec-324fe5b9783c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 💾 Save Agent Output to Table\n",
    "\n",
    "This cell saves the agent's underwriting decision into the `agent_review` table in Unity Catalog.\n",
    "\n",
    "- **Steps:**\n",
    "  1. Creates a single-row DataFrame with `quote_id` and `agent_output`\n",
    "  2. Registers it as a temporary view (`new_review_data`)\n",
    "  3. Executes a `MERGE` to upsert the result into `lrcatalog.agentic_underwriting.agent_review`\n",
    "\n",
    "- **Use case:** Stores decisions and justifications made by the agent for audit, governance, or follow-up review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b677ed3-da56-46ca-b820-d6ffe4368e73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#save output into a table\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Create a Spark DataFrame with new output\n",
    "row = Row(quote_id=quote_id, agent_output=agent_output)\n",
    "new_data = spark.createDataFrame([row])\n",
    "\n",
    "# Register as temp view for merge\n",
    "new_data.createOrReplaceTempView(\"new_review_data\")\n",
    "\n",
    "# Run MERGE to update or insert\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO lrcatalog.agentic_underwriting.agent_review AS target\n",
    "USING new_review_data AS source\n",
    "ON target.quote_id = source.quote_id\n",
    "WHEN MATCHED THEN UPDATE SET target.agent_output = source.agent_output\n",
    "WHEN NOT MATCHED THEN INSERT (quote_id, agent_output) VALUES (source.quote_id, source.agent_output)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838f8eee-044a-4c2d-a933-8d93b6d46aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result_summary = {\n",
    "    \"status\": \"success\",\n",
    "    \"quote_id\": quote_id,\n",
    "    \"catalog\": catalog,\n",
    "    \"schema\": schema,\n",
    "    \"table\": \"underwriting_results\"\n",
    "}\n",
    "\n",
    "dbutils.notebook.exit(json.dumps(result_summary))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks-agents",
     "databricks-openai",
     "databricks_langchain",
     "mlflow"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "2. Agentic Underwriting Pipeline",
   "widgets": {
    "catalog": {
     "currentValue": "lrcatalog",
     "nuid": "b6bfa8a0-85c6-4559-8da6-77857b5c930d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "lrcatalog",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "lrcatalog",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "quote_id": {
     "currentValue": "R9999",
     "nuid": "c0bbb389-6c25-4478-a60b-bb7da064c61b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "R9999",
      "label": null,
      "name": "quote_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "R9999",
      "label": null,
      "name": "quote_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "agentic_underwriting",
     "nuid": "c8349f07-1ddb-4234-b7b2-53f06d8df602",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "agentic_underwriting",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "agentic_underwriting",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
